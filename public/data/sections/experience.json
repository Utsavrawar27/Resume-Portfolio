{
    "articles": [
        {
            "id": 1,
            "component": "ArticleTimeline",
            "locales": {},
            "settings": {
                "order_items_by": "id",
                "order_items_sort": "desc"
            },
            "items": [
                {
                    "id": 1,
                    "dateStart": {"year": 2025, "month": 6},
                    "dateEnd": {"year": 2025, "month": 9},
                    "img": null,
                    "fallbackFaIcon": "fa-solid fa-code",
                    "fallbackFaIconColor": "#007BFF",

                    "locales": {
                        "en": {
                            "title": "Software Developer – Data",
                            "description": "Building scalable <strong>data infrastructure</strong> on AWS, leveraging services like S3, Lambda, Glue, and Snowflake for efficient ingestion, transformation, and storage of multi-source data at scale.",
                            "list": {
                                "title": "Key Achievements",
                                "items": [
                                    "Built data infrastructure on AWS, leveraging services like S3, Lambda, Glue, and Snowflake for efficient ingestion, transformation, and storage of multi-source data at scale.",
                                    "Designed and orchestrated scalable ETL pipelines using PySpark to process JSON snapshots from S3 into partitioned datasets, seamlessly integrated with Snowflake external tables for optimized querying and automated partition management.",
                                    "Contributed to scheduling hourly Airflow DAGs for reliable data processing.",
                                    "Automated ingestion and processing of irregular partner audit CSVs, eliminating manual effort and enabling real-time compliance monitoring with Slack alerts and always up-to-date dashboards for rapid risk triage."
                                ]
                            },
                            "province": "Remote",
                            "country": "US",
                            "institution": "Open It Labs llc",
                            "tags": ["AWS", "S3", "Lambda", "Glue", "Snowflake", "PySpark", "ETL", "Airflow", "Data Infrastructure"]
                        },

                        "es": {
                            "title": "Desarrollador de Software – Datos",
                            "description": "Construyendo <strong>infraestructura de datos escalable</strong> en AWS, aprovechando servicios como S3, Lambda, Glue y Snowflake para la ingesta, transformación y almacenamiento eficiente de datos multi-fuente a escala.",
                            "list": {
                                "title": "Logros Clave",
                                "items": [
                                    "Construí infraestructura de datos en AWS, aprovechando servicios como S3, Lambda, Glue y Snowflake para la ingesta, transformación y almacenamiento eficiente de datos multi-fuente a escala.",
                                    "Diseñé y orquesté pipelines ETL escalables usando PySpark para procesar instantáneas JSON desde S3 en conjuntos de datos particionados, integrados perfectamente con tablas externas de Snowflake para consultas optimizadas y gestión automatizada de particiones.",
                                    "Contribuí a la programación de DAGs de Airflow por hora para procesamiento confiable de datos.",
                                    "Automaticé la ingesta y procesamiento de CSVs de auditoría de socios irregulares, eliminando esfuerzo manual y habilitando monitoreo de cumplimiento en tiempo real con alertas de Slack y dashboards siempre actualizados para triage rápido de riesgos."
                                ]
                            },
                            "province": "Remoto",
                            "country": "EE. UU.",
                            "institution": "Open It Labs llc",
                            "tags": ["AWS", "S3", "Lambda", "Glue", "Snowflake", "PySpark", "ETL", "Airflow", "Infraestructura de Datos"]
                        },

                        "fr": {
                            "title": "Développeur Logiciel – Données",
                            "description": "Construction d'une <strong>infrastructure de données évolutive</strong> sur AWS, exploitant des services comme S3, Lambda, Glue et Snowflake pour l'ingestion, la transformation et le stockage efficaces de données multi-sources à grande échelle.",
                            "list": {
                                "title": "Réalisations Clés",
                                "items": [
                                    "Construit une infrastructure de données sur AWS, exploitant des services comme S3, Lambda, Glue et Snowflake pour l'ingestion, la transformation et le stockage efficaces de données multi-sources à grande échelle.",
                                    "Conçu et orchestré des pipelines ETL évolutifs utilisant PySpark pour traiter des instantanés JSON depuis S3 en ensembles de données partitionnés, intégrés de manière transparente avec des tables externes Snowflake pour des requêtes optimisées et une gestion automatisée des partitions.",
                                    "Contribué à la planification de DAGs Airflow horaires pour un traitement fiable des données.",
                                    "Automatisé l'ingestion et le traitement de CSVs d'audit de partenaires irréguliers, éliminant l'effort manuel et permettant une surveillance de conformité en temps réel avec des alertes Slack et des tableaux de bord toujours à jour pour un triage rapide des risques."
                                ]
                            },
                            "province": "Distant",
                            "country": "États-Unis",
                            "institution": "Open It Labs llc",
                            "tags": ["AWS", "S3", "Lambda", "Glue", "Snowflake", "PySpark", "ETL", "Airflow", "Infrastructure de Données"]
                        },

                        "zh": {
                            "title": "软件开发者 – 数据",
                            "description": "在AWS上构建可扩展的<strong>数据基础设施</strong>，利用S3、Lambda、Glue和Snowflake等服务，高效地摄取、转换和存储多源数据。",
                            "list": {
                                "title": "主要成就",
                                "items": [
                                    "在AWS上构建数据基础设施，利用S3、Lambda、Glue和Snowflake等服务，高效地摄取、转换和存储多源数据。",
                                    "使用PySpark设计和编排可扩展的ETL管道，将S3中的JSON快照处理为分区数据集，与Snowflake外部表无缝集成，实现优化的查询和自动化分区管理。",
                                    "参与调度每小时Airflow DAG，实现可靠的数据处理。",
                                    "自动化不规则合作伙伴审计CSV的摄取和处理，消除手动工作，通过Slack警报和始终更新的仪表板实现实时合规监控，快速进行风险分类。"
                                ]
                            },
                            "province": "远程",
                            "country": "美国",
                            "institution": "Open It Labs llc",
                            "tags": ["AWS", "S3", "Lambda", "Glue", "Snowflake", "PySpark", "ETL", "Airflow", "数据基础设施"]
                        }
                    }
                },

                {
                    "id": 2,
                    "dateStart": {"year": 2024, "month": 9},
                    "dateEnd": {"year": 2025, "month": 6},
                    "img": "images/places/SJSU.jpg",
                    "fallbackFaIcon": "fa-solid fa-graduation-cap",
                    "fallbackFaIconColor": "#0055A4",

                    "locales": {
                        "en": {
                            "title": "Research Assistant – Task Atlas AI",
                            "description": "Designed and implemented a scalable <strong>full stack web application</strong> to analyze task level automation susceptibility across occupations, leveraging structured labor datasets and AI risk models.",
                            "list": {
                                "title": "Key Achievements",
                                "items": [
                                    "Designed and implemented a scalable full stack web application to analyze task level automation susceptibility across occupations, leveraging structured labor datasets and AI risk models.",
                                    "Developed a microservices-based backend architecture in Django Python integrating OpenAI API to score tasks on AI replaceability based on dimensions like cognitive complexity, required skills, and routine level.",
                                    "Engineered ETL pipelines to ingest, clean, and normalize large occupational datasets, and stored them in a relational PostgreSQL database with optimized indexing and partitioning for analytical performance.",
                                    "Structured and populated a relational database to store professions, tasks, skills, and AI replacement metrics, ensuring efficient data retrieval and scalability.",
                                    "Defined and implemented data models and schemas to support task-profession relationships, AI risk metrics, and classification categories, ensuring data consistency and normalization across entities.",
                                    "Focused on user experience and system performance, ensuring the platform is both intuitive and robust for analytical exploration.",
                                    "Delivered technical documentation and deployment automation scripts Docker and CI/CD pipelines to support reproducibility and scalability across academic and enterprise use cases."
                                ]
                            },
                            "province": "San Jose, California",
                            "country": "US",
                            "institution": "San Jose State University",
                            "tags": ["Python", "Django", "PostgreSQL", "ETL", "OpenAI API", "Full Stack", "Docker", "CI/CD", "Data Modeling"]
                        },

                        "es": {
                            "title": "Asistente de Investigación – Task Atlas AI",
                            "description": "Diseñé e implementé una <strong>aplicación web full stack escalable</strong> para analizar la susceptibilidad de automatización a nivel de tareas en diferentes ocupaciones, aprovechando conjuntos de datos laborales estructurados y modelos de riesgo de IA.",
                            "list": {
                                "title": "Logros Clave",
                                "items": [
                                    "Diseñé e implementé una aplicación web full stack escalable para analizar la susceptibilidad de automatización a nivel de tareas en diferentes ocupaciones, aprovechando conjuntos de datos laborales estructurados y modelos de riesgo de IA.",
                                    "Desarrollé una arquitectura backend basada en microservicios en Django Python integrando la API de OpenAI para puntuar tareas en reemplazabilidad por IA basado en dimensiones como complejidad cognitiva, habilidades requeridas y nivel de rutina.",
                                    "Ingeniericé pipelines ETL para ingerir, limpiar y normalizar grandes conjuntos de datos ocupacionales, y los almacené en una base de datos relacional PostgreSQL con indexación y particionamiento optimizados para rendimiento analítico.",
                                    "Estructuré y poblé una base de datos relacional para almacenar profesiones, tareas, habilidades y métricas de reemplazo por IA, asegurando recuperación eficiente de datos y escalabilidad.",
                                    "Definí e implementé modelos y esquemas de datos para soportar relaciones tarea-profesión, métricas de riesgo de IA y categorías de clasificación, asegurando consistencia de datos y normalización entre entidades.",
                                    "Me enfoqué en la experiencia del usuario y el rendimiento del sistema, asegurando que la plataforma sea tanto intuitiva como robusta para exploración analítica.",
                                    "Entregué documentación técnica y scripts de automatización de despliegue Docker y pipelines CI/CD para soportar reproducibilidad y escalabilidad en casos de uso académicos y empresariales."
                                ]
                            },
                            "province": "San Jose, California",
                            "country": "EE. UU.",
                            "institution": "San Jose State University",
                            "tags": ["Python", "Django", "PostgreSQL", "ETL", "API OpenAI", "Full Stack", "Docker", "CI/CD", "Modelado de Datos"]
                        },

                        "fr": {
                            "title": "Assistant de Recherche – Task Atlas AI",
                            "description": "Conçu et implémenté une <strong>application web full stack évolutive</strong> pour analyser la susceptibilité d'automatisation au niveau des tâches à travers les professions, exploitant des ensembles de données de travail structurés et des modèles de risque IA.",
                            "list": {
                                "title": "Réalisations Clés",
                                "items": [
                                    "Conçu et implémenté une application web full stack évolutive pour analyser la susceptibilité d'automatisation au niveau des tâches à travers les professions, exploitant des ensembles de données de travail structurés et des modèles de risque IA.",
                                    "Développé une architecture backend basée sur les microservices en Django Python intégrant l'API OpenAI pour noter les tâches sur la remplaçabilité par IA basée sur des dimensions comme la complexité cognitive, les compétences requises et le niveau de routine.",
                                    "Ingéniéré des pipelines ETL pour ingérer, nettoyer et normaliser de grands ensembles de données professionnelles, et les stockés dans une base de données relationnelle PostgreSQL avec indexation et partitionnement optimisés pour les performances analytiques.",
                                    "Structuré et peuplé une base de données relationnelle pour stocker les professions, tâches, compétences et métriques de remplacement IA, assurant une récupération efficace des données et l'évolutivité.",
                                    "Défini et implémenté des modèles et schémas de données pour supporter les relations tâche-profession, métriques de risque IA et catégories de classification, assurant la cohérence des données et la normalisation entre entités.",
                                    "Concentré sur l'expérience utilisateur et les performances du système, assurant que la plateforme est à la fois intuitive et robuste pour l'exploration analytique.",
                                    "Livré une documentation technique et des scripts d'automatisation de déploiement Docker et pipelines CI/CD pour supporter la reproductibilité et l'évolutivité dans les cas d'usage académiques et d'entreprise."
                                ]
                            },
                            "province": "San Jose, Californie",
                            "country": "États-Unis",
                            "institution": "San Jose State University",
                            "tags": ["Python", "Django", "PostgreSQL", "ETL", "API OpenAI", "Full Stack", "Docker", "CI/CD", "Modélisation de Données"]
                        },

                        "zh": {
                            "title": "研究助理 – Task Atlas AI",
                            "description": "设计并实现了一个可扩展的<strong>全栈Web应用程序</strong>，用于分析跨职业的任务级自动化易感性，利用结构化劳动力数据集和AI风险模型。",
                            "list": {
                                "title": "主要成就",
                                "items": [
                                    "设计并实现了一个可扩展的全栈Web应用程序，用于分析跨职业的任务级自动化易感性，利用结构化劳动力数据集和AI风险模型。",
                                    "在Django Python中开发了基于微服务的后端架构，集成OpenAI API，根据认知复杂性、所需技能和常规水平等维度对任务的AI可替代性进行评分。",
                                    "设计了ETL管道来摄取、清理和规范化大型职业数据集，并将它们存储在关系型PostgreSQL数据库中，具有优化的索引和分区以提高分析性能。",
                                    "构建并填充了关系数据库以存储职业、任务、技能和AI替代指标，确保高效的数据检索和可扩展性。",
                                    "定义并实现了数据模型和模式，以支持任务-职业关系、AI风险指标和分类类别，确保跨实体的数据一致性和规范化。",
                                    "专注于用户体验和系统性能，确保平台既直观又强大，适合分析探索。",
                                    "交付了技术文档和部署自动化脚本Docker和CI/CD管道，以支持学术和企业用例的可重现性和可扩展性。"
                                ]
                            },
                            "province": "加利福尼亚州圣何塞",
                            "country": "美国",
                            "institution": "San Jose State University",
                            "tags": ["Python", "Django", "PostgreSQL", "ETL", "OpenAI API", "全栈", "Docker", "CI/CD", "数据建模"]
                        }
                    }
                },

                {
                    "id": 3,
                    "dateStart": {"year": 2019, "month": 8},
                    "dateEnd": {"year": 2022, "month": 6},
                    "img": "images/places/Subex-logo.png",
                    "fallbackFaIcon": "fa-solid fa-code",
                    "fallbackFaIconColor": "#FF6B35",


                    "locales": {
                        "en": {
                            "title": "Software Development Engineer",
                            "description": "Developed and maintained <strong>highly scalable backend services</strong> for <strong>Optus mobile</strong> serving 11M+ users, using Java, Spring Boot, and microservices architecture. Led initiatives to optimize fraud detection systems, implement event-driven processing, and architect resilient microservices-based solutions.",
                            "list": {
                                "title": "Key Achievements",
                                "items": [
                                    "Developed and maintained <strong>highly scalable backend services</strong> for Optus mobile, serving 11M+ users, using Java, Spring Boot, and microservices architecture.",
                                    "Optimized <strong>fraud detection performance</strong>, replacing synchronous API calls with Kafka-based event-driven processing, reducing fraud alert delays by 15%.",
                                    "Architected a <strong>resilient microservices-based system</strong> with Docker, Kubernetes, and Jenkins CI/CD pipeline, leading to an 80% improvement in system uptime.",
                                    "Designed and implemented <strong>RESTful APIs</strong> to facilitate seamless third-party service integration and new feature rollouts.",
                                    "Implemented <strong>OAuth 2 for secure user authentication</strong> and authorization, increasing industry security standards by 60%.",
                                    "Led the <strong>migration of databases</strong>, realizing a remarkable 30% optimization in data storage and retrieval for specific use cases.",
                                    "Implemented <strong>gRPC protocol</strong> to handle big data collections and real-time communication more effectively.",
                                    "Integrated <strong>connection pooling using HikariCP</strong> to manage database connections resolving critical production issues.",
                                    "Cut deployment costs by <strong>$2K/month</strong> through containerized microservices and auto-scaling optimizations.",
                                    "Optimized <strong>MongoDB queries</strong> by implementing compound indexes, query tuning, and sharding, reducing execution time from 5-7 seconds to 2-3 seconds."
                                ]
                            },
                            "province": "Bangalore",
                            "country": "India",
                            "institution": "Subex Limited",
                            "tags": ["Java", "Spring Boot", "Kafka", "Docker", "Kubernetes", "OAuth 2", "gRPC", "MongoDB", "Fraud Detection", "Microservices"]
                        },

                        "es": {
                            "title": "Ingeniero de Desarrollo de Software",
                            "description": "Desarrollé y mantuve <strong>servicios backend altamente escalables</strong> para <strong>Optus mobile</strong> sirviendo a más de 11 millones de usuarios, utilizando Java, Spring Boot y arquitectura de microservicios. Lideré iniciativas para optimizar sistemas de detección de fraudes, implementar procesamiento basado en eventos y arquitectar soluciones resilientes basadas en microservicios.",
                            "list": {
                                "title": "Logros Clave",
                                "items": [
                                    "Desarrollé y mantuve <strong>servicios backend altamente escalables</strong> para Optus mobile, sirviendo a más de 11 millones de usuarios, utilizando Java, Spring Boot y arquitectura de microservicios.",
                                    "Optimicé el <strong>rendimiento de detección de fraudes</strong>, reemplazando llamadas API síncronas con procesamiento basado en eventos Kafka, reduciendo los retrasos de alertas de fraude en un 15%.",
                                    "Arquitecturé un <strong>sistema resiliente basado en microservicios</strong> con Docker, Kubernetes y pipeline CI/CD Jenkins, logrando una mejora del 80% en tiempo de actividad del sistema.",
                                    "Diseñé e implementé <strong>APIs RESTful</strong> para facilitar la integración perfecta de servicios de terceros y despliegues de nuevas características.",
                                    "Implementé <strong>OAuth 2 para autenticación segura de usuarios</strong> y autorización, aumentando los estándares de seguridad de la industria en un 60%.",
                                    "Lideré la <strong>migración de bases de datos</strong>, logrando una notable optimización del 30% en almacenamiento y recuperación de datos para casos específicos.",
                                    "Implementé <strong>protocolo gRPC</strong> para manejar colecciones de big data y comunicación en tiempo real de manera más efectiva.",
                                    "Integré <strong>pooling de conexiones usando HikariCP</strong> para gestionar conexiones de base de datos resolviendo problemas críticos de producción.",
                                    "Reduje los costos de despliegue en <strong>$2K/mes</strong> a través de microservicios containerizados y optimizaciones de auto-escalado.",
                                    "Optimicé <strong>consultas MongoDB</strong> implementando índices compuestos, ajuste de consultas y sharding, reduciendo el tiempo de ejecución de 5-7 segundos a 2-3 segundos."
                                ]
                            },
                            "province": "Bangalore",
                            "country": "India",
                            "institution": "Subex Limited",
                            "tags": ["Java", "Spring Boot", "Kafka", "Docker", "Kubernetes", "OAuth 2", "gRPC", "MongoDB", "Detección de Fraudes", "Microservicios"]
                        },

                        "fr": {
                            "title": "Ingénieur de Développement Logiciel",
                            "description": "Développé et maintenu des <strong>services backend hautement évolutifs</strong> pour <strong>Optus mobile</strong> servant plus de 11 millions d'utilisateurs, utilisant Java, Spring Boot et l'architecture de microservices. Dirigé des initiatives pour optimiser les systèmes de détection de fraude, implémenter le traitement basé sur les événements et architecturer des solutions résilientes basées sur les microservices.",
                            "list": {
                                "title": "Réalisations Clés",
                                "items": [
                                    "Développé et maintenu des <strong>services backend hautement évolutifs</strong> pour Optus mobile, servant plus de 11 millions d'utilisateurs, utilisant Java, Spring Boot et l'architecture de microservices.",
                                    "Optimisé les <strong>performances de détection de fraude</strong>, remplaçant les appels API synchrones par un traitement basé sur les événements Kafka, réduisant les délais d'alerte de fraude de 15%.",
                                    "Architecturé un <strong>système résilient basé sur les microservices</strong> avec Docker, Kubernetes et pipeline CI/CD Jenkins, conduisant à une amélioration de 80% du temps de fonctionnement du système.",
                                    "Conçu et implémenté des <strong>APIs RESTful</strong> pour faciliter l'intégration transparente de services tiers et les déploiements de nouvelles fonctionnalités.",
                                    "Implémenté <strong>OAuth 2 pour l'authentification sécurisée des utilisateurs</strong> et l'autorisation, augmentant les standards de sécurité de l'industrie de 60%.",
                                    "Dirigé la <strong>migration des bases de données</strong>, réalisant une optimisation remarquable de 30% dans le stockage et la récupération de données pour des cas d'usage spécifiques.",
                                    "Implémenté le <strong>protocole gRPC</strong> pour gérer plus efficacement les collections de big data et la communication en temps réel.",
                                    "Intégré le <strong>pooling de connexions utilisant HikariCP</strong> pour gérer les connexions de base de données résolvant les problèmes critiques de production.",
                                    "Réduit les coûts de déploiement de <strong>$2K/mois</strong> grâce aux microservices conteneurisés et optimisations d'auto-scaling.",
                                    "Optimisé les <strong>requêtes MongoDB</strong> en implémentant des index composés, le réglage de requêtes et le sharding, réduisant le temps d'exécution de 5-7 secondes à 2-3 secondes."
                                ]
                            },
                            "province": "Bangalore",
                            "country": "Inde",
                            "institution": "Subex Limited",
                            "tags": ["Java", "Spring Boot", "Kafka", "Docker", "Kubernetes", "OAuth 2", "gRPC", "MongoDB", "Détection de Fraude", "Microservices"]
                        },

                        "zh": {
                            "title": "软件开发工程师",
                            "description": "使用Java、Spring Boot和微服务架构为<strong>Optus移动</strong>开发和维护<strong>高度可扩展的后端服务</strong>，服务超过1100万用户。领导优化欺诈检测系统、实施事件驱动处理和架构弹性微服务解决方案的举措。",
                            "list": {
                                "title": "主要成就",
                                "items": [
                                    "使用Java、Spring Boot和微服务架构为Optus移动开发和维护<strong>高度可扩展的后端服务</strong>，服务超过1100万用户。",
                                    "优化<strong>欺诈检测性能</strong>，用基于Kafka的事件驱动处理替代同步API调用，将欺诈警报延迟减少15%。",
                                    "使用Docker、Kubernetes和Jenkins CI/CD管道架构<strong>弹性微服务系统</strong>，系统正常运行时间提高80%。",
                                    "设计并实施<strong>RESTful API</strong>以促进第三方服务的无缝集成和新功能发布。",
                                    "实施<strong>OAuth 2安全用户身份验证</strong>和授权，将行业安全标准提高60%。",
                                    "领导<strong>数据库迁移</strong>，在特定用例中实现数据存储和检索30%的显著优化。",
                                    "实施<strong>gRPC协议</strong>以更有效地处理大数据集合和实时通信。",
                                    "使用HikariCP集成<strong>连接池</strong>来管理数据库连接，解决关键生产问题。",
                                    "通过容器化微服务和自动扩展优化将部署成本削减<strong>每月$2K</strong>。",
                                    "通过实施复合索引、查询调优和分片优化<strong>MongoDB查询</strong>，将执行时间从5-7秒减少到2-3秒。"
                                ]
                            },
                            "province": "班加罗尔",
                            "country": "印度",
                            "institution": "Subex Limited",
                            "tags": ["Java", "Spring Boot", "Kafka", "Docker", "Kubernetes", "OAuth 2", "gRPC", "MongoDB", "欺诈检测", "微服务"]
                        }
                    }
                }
            ]
        }
    ]
}